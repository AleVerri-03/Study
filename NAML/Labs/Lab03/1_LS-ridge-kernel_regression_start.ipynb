{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C5ncMKPCGS_"
   },
   "source": [
    "# Moore-Penrose pseudo inverse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1666359091538,
     "user_tz": -120
    },
    "id": "mf3YmOwwWx3P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTAIp1RRBzfn"
   },
   "source": [
    "Write a function computing the Moore-Penrose pseudo inverse, exploiting the full SVD.\n",
    "\n",
    "$$A^\\dagger = V \\Sigma^{-1} U^T, \\quad A = U \\Sigma V^T$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1666359093537,
     "user_tz": -120
    },
    "id": "l53EKZ8m9v6X"
   },
   "outputs": [],
   "source": [
    "def my_pinv_fullSVD(A):\n",
    "# FILL HERE\n",
    "    return Pinv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pji4usPEFaPS"
   },
   "source": [
    "Write now a function computing the Moore-Penrose pseudo inverse, exploiting the reduced SVD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666359095044,
     "user_tz": -120
    },
    "id": "n-cfuhorCG0f"
   },
   "outputs": [],
   "source": [
    "def my_pinv_thinSVD(A):\n",
    "# FILL HERE\n",
    "    return Pinv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AiVbuB94CItY"
   },
   "source": [
    "Generate a random matrix $A$ (with elements sampled from a standard Gaussian distribution) with 5 rows and 4 columns. Compute its Moore-Penrose pseudo inverse thorugh the two functions above defined, and compare the result with the function `numpy.linalg.pinv` (see [Documentation](https://numpy.org/doc/stable/reference/generated/numpy.linalg.pinv.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 953,
     "status": "ok",
     "timestamp": 1666359097044,
     "user_tz": -120
    },
    "id": "56sxO58a87LU",
    "outputId": "c851ecf1-df21-4642-b638-39015b340fd2"
   },
   "outputs": [],
   "source": [
    "A = np.random.randn(5, 4)\n",
    "Apinv_numpy = np.linalg.pinv(A)\n",
    "Apinv_fullSVD = my_pinv_fullSVD(A)\n",
    "Apinv_thinSVD = my_pinv_thinSVD(A)\n",
    "print(np.linalg.norm(Apinv_numpy - Apinv_fullSVD) / np.linalg.norm(Apinv_numpy))\n",
    "print(np.linalg.norm(Apinv_numpy - Apinv_thinSVD) / np.linalg.norm(Apinv_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLqUjmIvCnCN"
   },
   "source": [
    "Compare the three implementations performances through the Google Colab magic command `%timeit`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhvfVtIo-NC1"
   },
   "outputs": [],
   "source": [
    "%timeit np.linalg.pinv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y21T3Nnj-aL-"
   },
   "outputs": [],
   "source": [
    "%timeit my_pinv_fullSVD(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5zzvnNMJ-dD7"
   },
   "outputs": [],
   "source": [
    "%timeit my_pinv_thinSVD(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2rYM4FpDI9M"
   },
   "source": [
    "# Least-square regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hquNEJ1sDN9I"
   },
   "source": [
    "Consider the linear model\n",
    "\n",
    "$$\n",
    "y = mx + q.\n",
    "$$\n",
    "\n",
    "where $m = 2$ and $q = 3$.\n",
    "\n",
    "Generate $N = 100$ points $x_i$, sampling from a standard Gaussian distribution, and the associated $y_i$. Then, add a synthetic noise ($\\epsilon_i$) by sampling from a Gaussian distribution with zero mean and standard deviation $\\sigma = 2$. Plot the noisy data $(x_i, \\tilde{y}_i)$, where $\\tilde{y}_i = y_i + \\epsilon_i$, in the $(x,y)$ plane, together with the line $y = mx + q$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1666359180375,
     "user_tz": -120
    },
    "id": "SRF2lfmNAH1M"
   },
   "outputs": [],
   "source": [
    "m = 2.0\n",
    "q = 3.0\n",
    "N = 100\n",
    "noise = 2.0\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8w-4ou8D20u"
   },
   "source": [
    "Using the previously implemented functions to compute the Moore-Penrose pseudo inverse, solve the least-squares problem\n",
    "\n",
    "$$\n",
    "\\min_{m,q} \\sum_{i=1}^N (\\tilde{y}_i - (m x_i + q))^2\n",
    "$$\n",
    "\n",
    "and display the regression line superimposed to the noisy data and the exact model. Define\n",
    "\n",
    "$$\\Phi = [\\mathbf{x}, \\mathbf{1}] \\in \\mathbb R^{N \\times 2}$$\n",
    "\n",
    "The least square problem is\n",
    "\n",
    "$$\\Phi \\mathbf{w} = \\mathbf{y}$$\n",
    "\n",
    "With solution\n",
    "\n",
    "$$\\mathbf{w} = \\Phi^\\dagger \\mathbf{y}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\mathbf{w} = [\\hat m, \\hat q]$$\n",
    "\n",
    "Notice that in general\n",
    "\n",
    "$$\\mathbf{y}^{Test} = \\Phi^{Test} \\mathbf{w}$$\n",
    "\n",
    "that in our case is equivalent to \n",
    "\n",
    "$$\\mathbf{y}_i^{Test} = \\hat{m} \\mathbf{x}_i^{Test} + \\hat{q}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1666359324904,
     "user_tz": -120
    },
    "id": "is1jvP_WAz4C",
    "outputId": "d199c633-4630-4645-8f36-c62e1f08ef42"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a scatter of the data points, the \"real\" linear model and the estimated linear model with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 344,
     "status": "ok",
     "timestamp": 1666359340197,
     "user_tz": -120
    },
    "id": "8X2JKmbQBRV-",
    "outputId": "18301b50-a7f6-4c48-f8c7-fad2d69b56bd"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-wssES11FISl"
   },
   "source": [
    "Repeat the excercise by solving the normal equations with `np.solve`. \n",
    "$$(\\Phi^T \\Phi)^{-1} \\mathbf{w} = \\Phi^T \\mathbf{y}$$\n",
    "Compare the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1666359421484,
     "user_tz": -120
    },
    "id": "B9HYqolhBia3",
    "outputId": "67b49663-e102-48d5-a065-2588cfede8c7"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5E5i7tk62e4"
   },
   "source": [
    "# Ridge regression and Kernel regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "793QCqaoIAGB"
   },
   "source": [
    "Consider the function\n",
    "\n",
    "$$\n",
    "y = f(x) = \\tanh(2x - 1).\n",
    "$$\n",
    "\n",
    "Generate $N = 100$ points $x_i$, sampling from a standard Gaussian distribution, and the associated $y_i$. Then, add a synthetic noise ($\\epsilon_i$) by sampling from a Gaussian distribution with zero mean and standard deviation $\\sigma = 0.1$. Plot the noisy data $(x_i, \\tilde{y}_i)$, where $\\tilde{y}_i = y_i + \\epsilon_i$, in the $(x,y)$ plane.\n",
    "\n",
    "Then, generate 1000 testing points, uniformly distributed in the interval $[-3,3]$, and display the function $y = f(x)$ in correspondence of the testing points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1666359459613,
     "user_tz": -120
    },
    "id": "cQ1mVije617U",
    "outputId": "708a8b6a-fcdf-4d4c-fb10-591594b2a2f7"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6SY2zU3I406"
   },
   "source": [
    "Proceeding as in the previous exercise, compute the regression line resulting from the **least squares regression** of data $(x_i, \\tilde{y}_i)$. Plot the resulting regression line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1666359500927,
     "user_tz": -120
    },
    "id": "XKgk85JyJXty",
    "outputId": "bfea6861-fa97-4de1-9c47-c8d7128cd155"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ERGPDoiwJv-O"
   },
   "source": [
    "Let us now consider **ridge regression**, corresponding to a regularizaton parameter $\\lambda = 1.0$.\n",
    "Solve the equations in two ways:\n",
    "1. Using the normal equations\n",
    "$$[(\\Phi^T \\Phi) + \\lambda I] \\mathbf{w} = \\Phi^T \\mathbf{y}$$\n",
    "2. Using the Woodbury idenitity to write the normal equations in \"kernel-form\"\n",
    "$$\\mathbf{w} = \\Phi^T \\boldsymbol{\\alpha}, \\quad [(\\Phi \\Phi^T) + \\lambda I] \\boldsymbol{\\alpha} = \\mathbf{y}$$\n",
    "\n",
    "Check that the two approaches lead to the same result.\n",
    "Compare the obtained regression line with the one obtained through least squares regression when changing $\\lambda$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1666359948339,
     "user_tz": -120
    },
    "id": "G_HmhHEHKLsX",
    "outputId": "8cdfb55d-ebb4-49b4-c8a0-d13dd02122a5"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_c7X6mmPKXiC"
   },
   "source": [
    "Consider now **kernel regression**.\n",
    "\n",
    "$$(K + \\lambda I) \\boldsymbol{\\alpha} = \\mathbf{y}$$\n",
    "\n",
    "Where $K_{ij} = \\mathcal{K}(x_i, x_j)$ and we consider\n",
    "\n",
    "1. The scalar product kernel\n",
    "   $$\\mathcal{K}(x_i, x_j) = x_i x_j + 1.$$\n",
    "\n",
    "2. The higher-order scalar product kernel, for $q > 1$.\n",
    "   $$\\mathcal{K}(x_i, x_j) = (x_i x_j + 1)^q.$$\n",
    "\n",
    "3. The Gaussian kernel, for $\\sigma > 0$.\n",
    "   $$\\mathcal{K}(x_i, x_j) = \\exp\\left(-\\frac{(x_i - x_j)^2}{2 \\sigma^2}\\right).$$\n",
    "\n",
    "\n",
    "The evaluation on the test data-point $\\hat{x}$ is computed as \n",
    "\n",
    "$$\\hat{\\mathbf{y}} = \\sum_{i = 1}^N \\alpha_i \\mathcal{K}(\\hat{x}, x_i) = K^{Test} \\boldsymbol{\\alpha}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "executionInfo": {
     "elapsed": 1165,
     "status": "ok",
     "timestamp": 1666360301465,
     "user_tz": -120
    },
    "id": "L-bazLFG7MYj",
    "outputId": "88ef3669-043a-4b63-a9be-95eeb37a9c5c"
   },
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an advance homework, try to write the matrix $K$ without using a for loop.\n",
    "Hint: you have to rewrite the kernel function $\\mathcal{K}$ to work with matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN46AwEpjEnW/c0wEG838xX",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
